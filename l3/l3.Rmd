---
title: "Лабораторная работа №3"
author: "Полянцев И.С."
date: "27 12 2020"
output: word_document
---

```{r setup, include=FALSE}
# Загрузка библиотек
library('lmtest')     # тесты остатков: bptest(), dwtest()
library('broom')      # трансформации данных: augment()
library('car')        # тест на мультиколинеарность: vif()
library('sandwich')   # оценки модели с поправкой на гетероскедастичность: vcovHC()
knitr::opts_chunk$set(echo = FALSE)
```

# Раздел I.

Создать скрипт .Rmd, который генерирует отчёт в формате Word по регрессионному анализу данных варианта. Для 2-4 лучших моделей, полученных в лабораторной работе №2, провести тесты остатков.

```{r}
load('l2_Полянцев.RData')

#  цикл по моделям в списке models.list
for (i in 1:length(models.list)) {
    # открываем вывод в файл
    png(paste('RPlot', i, '.png', sep = ''), height = 500, width = 500)
    
    # делим полотно на четыре части
    par(mfrow = c(2, 2))
    
    # рисуем 4 графика для одной и той же модели
    plot(models.list[[i]], 1)
    plot(models.list[[i]], 2)
    plot(models.list[[i]], 3)
    plot(models.list[[i]], 5)
    
    # добавляем общий заголовок с названием модели
    mtext(paste('Остатки модели ', names(models.list)[i], sep = ''), 
          side = 3, line = -2, outer = TRUE, cex = 1.2)
    par(mfrow = c(1, 1))
    
    # закрываем вывод в файл
    dev.off()
}
```

В пятой модели обнаруживаются два влияющих наблюдения: регионы 83 и 87

```{r}
DF[rownames(DF) %in% c(83, 87), c('Label', 'FO')]
```

Проверим, нужно ли исключать эти наблюдения:

```{r}
# работаем с 5 моделью
# найдём расстояния Кука для влияющих регионов
h <- augment(models.list[[5]], reg.df)
lev <- h[rownames(reg.df) %in% c(83, 87), '.cooksd', drop = F]

n <- nrow(reg.df)
k <- nrow(summary(models.list[[5]])$coeff)
f.tabl <- qf(1 - 0.05, df1 = k, df2 = n - k)

# сравниваем расчётные значения с порогами
cbind(leverage = round(lev,2), f.tabl = round(f.tabl,2),
      p.val = round(pf(lev$.cooksd, df1 = k, df2 = n - k), 4))
```

Поскольку расстояния Кука не превосходят критическую границу (и, следовательно, соответствующие p-значения больше 0,05), принимаем нулевые гипотезы для регионов 83 и 87: их не стоит убирать из выборки для построения пятой модели.

Проверим гипотезу о равенстве среднего остатков нулю для модели 1

```{r}
# 3. Проверка равенства среднего остатков нулю  --------------------------------

# номер модели
i <- 1
# t-тест для среднего
t.test(models.list[[i]]$residuals, mu = 0, alternative = 'two.sided')



# 3. Проверка постоянства среднего остатков ------------------------------------

# номер модели
i <- 1
# первая половина остатков
res.s1 <- models.list[[1]]$residuals[1:(n / 2)]

# вторая половина остатков
res.s2 <- models.list[[1]]$residuals[(n / 2):n]

# t-тест для равенства средних
t.test(res.s1, res.s2, alternative = 'two.sided')
```

P-значение для модели 1 > 0,05, следовательно нулевая гипотеза не отклоняется

Проведем тесты на гетероскедастичность для 2 модели:

```{r}
bptest(models.list[[2]])
```

Согласно первому тесту, P-значение < 0.05, следовательно, нулевая гипотеза отклоняется и в остатках модели 2 есть гетероскедастичность. Далее проведем тест Уайта

```{r}
# добавляем в исходную таблицу h прогнозы, остатки из модели model
h <- augment(models.list[[2]], reg.df)
bptest(models.list[[2]], data = h, 
       varformula = ~ GRP + I(GRP^2))

```

Этот тест внезапно показывает, что гетероскедастичности нет. Далее тест Голдфельда-Квандта

```{r}
gqtest(models.list[[2]], order.by = ~ GRP, 
       data = h, fraction = 0.2)
```

Результат тест Г-К вновь показывает, что присутствует гетероскедастичность. Далее - тест Глейзера

```{r}
# Тест Глейзера 
# вектор степеней независимой переменной
beta.vector <- seq(-1, 1.5, by = 0.05)
beta.vector <- beta.vector[beta.vector != 0]

# строим вспомогательные регрессии, и если коэффициент модели 
#  значим, выводим p-значение и степень.
#  для моделей 1-2 X: Rural.2011; для моделей 3-4 X: Injury.2011
for (j in 1:length(beta.vector)) {
    gl.test <- lm(abs(.std.resid) ~ I(GRP^beta.vector[j]), data = h)
    if (summary(gl.test)$coef[2, 4] < 0.05) {
        # если найдена значимая модель по тесту Глейзера,
        #  появится сообщение в консоли
        message(paste0('! >>> Модель значима >>> ', 
                      'beta = ', round(beta.vector[j], 2), 
                      'p-value = ', round(summary(gl.test)$coef[2, 4], 4)))
    } else {
        # если модель незначима, тоже пишем в консоль
        message(paste0('Модель для beta = ', round(beta.vector[j], 2), 
                       ' незначима'))
    }
}
```

Поскольку ни одна из вспомогательных регрессий для теста Глейзера не оказалась значимой, нулевая гипотеза (остатки гомоскедастичны) не отвергается

Проверим модель 3 на автокорреляцию

```{r}
# номер модели в списке
i <- 3

# тест Дарбина-Уотсона на автокорреляцию
dwtest(models.list[[i]], alternative = 'two.sided')

# автокорреляционный коэффициент первого порядка для остатков
n <- nrow(reg.df)
cor.test(x = models.list[[i]]$residuals[1:(n - 1)],
         y = models.list[[i]]$residuals[2:n])
```

P-значение > 0.05 => нулевая гипотеза не отклоняется и в остатках 3 модели отсутствует автокорреляция первого порядка

Переоценка параметров модели 1 с учетом ошибок

```{r}
# 6. Переоценка параметров модели с учётом ошибок  -----------------------------

# оценки параметров модели по МНК. для примера: модель 1
i <- 1

# исходные коэффициенты и их стандартные ошибки
coeftest(models.list[[i]])

# робастные оценки стандартных ошибок моделей
# vcovHC(): оценка ковариационной матриц, устойчивая к гетероскедастичности
# vcovHAC(): оценка ковариационной матриц, устойчивая к гетероскедастичности
#  и автокорреляции
coeftest(models.list[[i]], vcov. = vcovHAC(models.list[[i]])) # гетероскедастичность и автокорреляция
# NB: сами оценки параметров не меняются,
#  меняются их стандартные ошибки, и выводы по значимости могут измениться
```

Тест на мультиколлинеарность факторов модели 6
```{r}
# VIF-тест на мультиколлинеарность факторов 
#  NB: применяется для множественной регрессии с непрерывными факторами
round(vif(models.list[[6]]), 2)
```
Поскольку значения VIF-коэффициентов равны 1, в модели 6 нет мультиколлинеарности факторов.